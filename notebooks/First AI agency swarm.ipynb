{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agency-swarm in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: gradio in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: requests in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.8.2)\n",
      "Requirement already satisfied: openai==1.30.4 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (1.30.4)\n",
      "Requirement already satisfied: instructor==1.3.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (1.3.2)\n",
      "Requirement already satisfied: datamodel-code-generator==0.25.6 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (0.25.6)\n",
      "Requirement already satisfied: deepdiff==6.7.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (6.7.1)\n",
      "Requirement already satisfied: termcolor==2.4.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (2.4.0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (1.0.1)\n",
      "Requirement already satisfied: rich==13.7.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (13.7.1)\n",
      "Requirement already satisfied: jsonref==1.1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from agency-swarm) (1.1.0)\n",
      "Requirement already satisfied: argcomplete<4.0,>=1.10 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (3.4.0)\n",
      "Requirement already satisfied: black>=19.10b0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (24.4.2)\n",
      "Requirement already satisfied: genson<2.0,>=1.2.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (1.3.0)\n",
      "Requirement already satisfied: inflect<6.0,>=4.1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (5.6.2)\n",
      "Requirement already satisfied: isort<6.0,>=4.3.21 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (5.13.2)\n",
      "Requirement already satisfied: jinja2<4.0,>=2.10.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (3.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (23.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datamodel-code-generator==0.25.6->agency-swarm) (6.0.1)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deepdiff==6.7.1->agency-swarm) (4.1.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor==1.3.2->agency-swarm) (3.9.5)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor==1.3.2->agency-swarm) (0.16)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor==1.3.2->agency-swarm) (2.20.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor==1.3.2->agency-swarm) (8.5.0)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor==1.3.2->agency-swarm) (0.12.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==1.30.4->agency-swarm) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich==13.7.1->agency-swarm) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from rich==13.7.1->agency-swarm) (2.17.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=5.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.111.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.23.5)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.10.6)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.5.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.1.0->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.1.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=5.0->gradio) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=5.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.30.4->agency-swarm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.30.4->agency-swarm) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor==1.3.2->agency-swarm) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor==1.3.2->agency-swarm) (1.5.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (2.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.2->agency-swarm) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.2->agency-swarm) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.2->agency-swarm) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.2->agency-swarm) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.2->agency-swarm) (1.9.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.25.6->agency-swarm) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.25.6->agency-swarm) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from black>=19.10b0->datamodel-code-generator==0.25.6->agency-swarm) (4.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0.0->typer<1.0.0,>=0.9.0->instructor==1.3.2->agency-swarm) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich==13.7.1->agency-swarm) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noell\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\noell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.22.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install agency-swarm gradio requests pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agency_swarm import set_openai_key\n",
    "from getpass import getpass\n",
    "set_openai_key(getpass(\"Please enter your openai key: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Manager Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesmgr_instructions = \"\"\"# SalesManager Agent Instructions\n",
    "\n",
    "You are an agent that oversees the entire sales process, communicates with other agents, and ensures that the sales data is loaded and analyzed.\n",
    "\n",
    "### Primary Instructions:\n",
    "2. Initiate communication with DataAnalystAgent to extract data from Wordpress and perform data analysis on the loaded sales data.\n",
    "3. Ensure the overall coordination and execution of tasks within the agency.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agency_swarm import Agent\n",
    "\n",
    "salesmgr = Agent(name=\"SalesManager\",\n",
    "            description=\"Oversees the entire sales process, communicates with other agents, and ensures that the sales data is loaded and analyzed.\",\n",
    "            instructions=salesmgr_instructions, # can be a file like ./instructions.md\n",
    "            files_folder=None,\n",
    "            tools=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom tools for sales loader agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions = \"\"\"# DataAnalyst Instructions\n",
    "\n",
    "You are an agent responsible for extracting, processing and analyzing the sales data. Your role is to use data analysis libraries to generate insights and reports.\n",
    "\n",
    "### Primary Instructions:\n",
    "1. Extract the data from Wordpress and prepare it for analysis.\n",
    "2. Process and analyze the data using data analysis libraries.\n",
    "3. Generate comprehensive reports and insights.\n",
    "4. Send the insights and reports to SalesManager for user communication.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom tools for sales agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agency_swarm.tools import BaseTool\n",
    "from pydantic import Field\n",
    "import pandas as pd\n",
    "\n",
    "class AnalyzeSalesData(BaseTool):\n",
    "    \"\"\"\n",
    "    This tool should analyze the sales data extracted by the DataExtractorAgent.\n",
    "    It should identify trends and insights from the sales data, such as sales patterns, high-performing products, and customer behavior.\n",
    "    The tool should return a structured report with the identified trends and insights.\n",
    "    \"\"\"\n",
    "\n",
    "    analyze: bool = Field(\n",
    "        ..., description=\"Yes if the tool should return detailed information about the analysis.\"\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        The implementation of the run method, where the tool's main functionality is executed.\n",
    "        This method analyzes the sales data to identify trends and insights, such as sales patterns, high-performing products, and customer behavior.\n",
    "        It returns a structured report with the identified trends and insights. Currency is assumed to be EUR.\n",
    "        \"\"\"\n",
    "        \n",
    "        sales_data = self.shared_state.get('sales_data')\n",
    "        # Convert sales data to a DataFrame for analysis\n",
    "        df = pd.DataFrame(sales_data)\n",
    "\n",
    "        # Ensure the DataFrame has the necessary columns\n",
    "        required_columns = ['Product ID', 'Product Name', 'Quantity', 'Order Date', 'Customer ID', 'Total', 'Net Revenue']\n",
    "        if not all(column in df.columns for column in required_columns):\n",
    "            return \"The sales data is missing one or more required columns.\"\n",
    "\n",
    "        # Convert column types\n",
    "        df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "        df['Total'] = pd.to_numeric(df['Total'], errors='coerce')\n",
    "        df['Net Revenue'] = pd.to_numeric(df['Net Revenue'], errors='coerce')\n",
    "        df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "\n",
    "        # Analyze sales patterns\n",
    "        sales_by_date = df.groupby(df['Order Date'].dt.date).agg({'Total': 'sum', 'Net Revenue': 'sum','Quantity': 'sum'}).reset_index()\n",
    "        sales_trend = sales_by_date.to_dict(orient='records')\n",
    "\n",
    "        # Identify high-performing products\n",
    "        top_products = df.groupby(['Product ID', 'Product Name']).agg({'Quantity': 'sum', 'Total': 'sum', 'Net Revenue': 'sum'}).reset_index()\n",
    "        top_products = top_products.sort_values(by='Total', ascending=False).head(10).to_dict(orient='records')\n",
    "        \n",
    "        # Calculate total revenue\n",
    "        total_income = df['Total'].sum()\n",
    "        net_revenue = df['Net Revenue'].sum()\n",
    "        sold_products = df['Quantity'].sum()\n",
    "\n",
    "        # Analyze customer behavior\n",
    "        # customer_sales = df.groupby('Customer ID').agg({'Total': 'sum', 'Quantity': 'sum'}).reset_index()\n",
    "        # customer_behavior = customer_sales.to_dict(orient='records')\n",
    "\n",
    "        # # Compile the report\n",
    "        report = {\n",
    "            \"sales_trend\": sales_trend,\n",
    "            \"sold_products\": sold_products,\n",
    "            \"top_products\": top_products,\n",
    "            \"total_income\": total_income,\n",
    "            \"net_revenue\": net_revenue\n",
    "        }\n",
    "\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agency_swarm.tools import BaseTool\n",
    "from pydantic import Field\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define global variables for authentication\n",
    "site_url = \"https://careup.online\"\n",
    "consumer_key = getpass(\"Please enter your consumer key: \")\n",
    "consumer_secret = getpass(\"Please enter your consumer secret: \")\n",
    "\n",
    "orders_endpoint = f'{site_url}/wp-json/wc/v3/orders'\n",
    "\n",
    "class ExtractSalesDataFromWordPress(BaseTool):\n",
    "    \"\"\"\n",
    "    This tool should extract sales data from WordPress using the WordPress API.\n",
    "    It should be able to authenticate with the WordPress site, query the necessary endpoints to retrieve sales data,\n",
    "    and handle any errors that may occur during the process. The data will be extracted according to a given date range,\n",
    "    which varies depending on the analysis type. The start date should be set 3 months before the period to be analyzed,\n",
    "    if the revenue is to be analyzed. The start date should be set to the same day of the first day of the period if the amount of sales is to be analyzed. \n",
    "    The extracted data should be returned as a summary of sales, as the data points might be too many. Note that revenue\n",
    "    is in euros.\n",
    "    \"\"\"\n",
    "\n",
    "    start_date_period: str = Field(\n",
    "        ..., description=\"The start date of the period to be analyzed, format: YYYY-MM-DDTHH:MM:SS.\"\n",
    "    )\n",
    "    \n",
    "    start_date_load: str = Field(\n",
    "        ..., description=\"The starting date of the sales to be loaded, format: YYYY-MM-DDTHH:MM:SS. If you want to analyze the revenue for a certain period of time,\"\n",
    "                        +\"set the start date 3 months ago. If you want to analyze the amount of sales made for a certain period, set the start date to the same day as the first day of the period.\"\n",
    "    )\n",
    "    \n",
    "    end_date: str = Field(\n",
    "        ..., description=\"The ending date of the sales to be loaded, format: YYYY-MM-DDTHH:MM:SS.\"\n",
    "    )\n",
    "    \n",
    "    revenue: bool = Field(\n",
    "        True, description=\"If you want to analyze the revenue, set this to True. If you want to analyze the amount of sales made, set this to False.\"\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        The implementation of the run method, where the tool's main functionality is executed.\n",
    "        This method authenticates with the WordPress site, queries the necessary endpoints to retrieve sales data,\n",
    "        and handles any errors that may occur during the process.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Assuming this script is located within the project directory\n",
    "        base_path = os.getcwd()\n",
    "        \n",
    "        # Check if base_path ends with 'data'\n",
    "        if base_path.endswith('data'):\n",
    "            base_path = os.path.dirname(base_path)\n",
    "\n",
    "        # Construct the relative path\n",
    "        self.shared_state.set('default_folder', base_path)\n",
    "        self.shared_state.set('data_folder', base_path + '/data')\n",
    "        os.chdir(self.shared_state.get('data_folder'))\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            sales_data = []\n",
    "            page = 1  # Start with the first page\n",
    "\n",
    "            while True:\n",
    "                # Parameters including the current page number and date range\n",
    "                params = {\n",
    "                    'per_page': 100,  # Number of orders per page (max 100)\n",
    "                    'status': 'completed',  # Retrieve only completed orders\n",
    "                    'orderby': 'date',\n",
    "                    'order': 'desc',\n",
    "                    'page': page,  # The current page to request\n",
    "                    'after': self.start_date,  # Filter orders created after this date\n",
    "                    'before': self.end_date   # Filter orders created before this date\n",
    "                }\n",
    "\n",
    "                response = requests.get(orders_endpoint, auth=HTTPBasicAuth(consumer_key, consumer_secret), params=params)\n",
    "                \n",
    "                # Get the orders from the response\n",
    "                orders = response.json()\n",
    "                \n",
    "                # Break if no more orders are returned (end of pages)\n",
    "                if not orders:\n",
    "                    break\n",
    "                \n",
    "                # Process orders on this page\n",
    "                for order in orders:\n",
    "                    order_id = order['id']\n",
    "                    order_date = order['date_created']\n",
    "\n",
    "                    # Get the date paid and total revenue for each order\n",
    "                    date_paid = order['date_paid']\n",
    "                    if self.revenue:\n",
    "                        if date_paid > self.end_date or date_paid < self.start_date_period or date_paid == None:\n",
    "                            continue\n",
    "                    total = order['total']\n",
    "                    customer_id = order['customer_id']\n",
    "                    line_items = order['line_items']\n",
    "                                    \n",
    "                    for item in line_items:\n",
    "                        product_id = item['product_id']\n",
    "                        product_name = item['name']\n",
    "                        quantity = item['quantity']\n",
    "                        net_revenue = item['total']\n",
    "                        \n",
    "                        # Add the data to the sales_data list\n",
    "                        sales_data.append({\n",
    "                            'Order ID': order_id,\n",
    "                            'Order Date': order_date,\n",
    "                            'Date Paid': date_paid,\n",
    "                            'Total': total,\n",
    "                            'Customer ID': customer_id,\n",
    "                            'Product ID': product_id,\n",
    "                            'Product Name': product_name,\n",
    "                            'Quantity': quantity,\n",
    "                            'Net Revenue': net_revenue\n",
    "                        })\n",
    "                \n",
    "                # Move to the next page\n",
    "                page += 1\n",
    "\n",
    "            # Return the extracted data in a structured format suitable for analysis\n",
    "            with open(\"./sales_data.json\", \"w\") as f:\n",
    "                json.dump(sales_data, f)\n",
    "            \n",
    "            self.shared_state.set('sales_data', sales_data)\n",
    "            os.chdir(base_path)\n",
    "            return sales_data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"An error occurred while extracting sales data: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Agent(name=\"DataAnalyst\",\n",
    "            description=\"Data Analyst is responsible for processing and analyzing the extracted sales data. This agent will use data analysis libraries to generate insights and reports.\",\n",
    "            instructions=analyst_instructions, # can be a file like ./instructions.md\n",
    "            files_folder=None,\n",
    "            tools=[ExtractSalesDataFromWordPress, AnalyzeSalesData])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_manifesto=\"\"\"# SalesDataAnalyzer Agency Manifesto\n",
    "\n",
    "The mission of SalesDataAnalyzer is to automate the process of analyzing sales data from Moterik. The agency will extract, process, and interpret sales data to provide actionable insights and reports. The ultimate goal is to enhance decision-making and improve sales strategies based on data-driven insights.\n",
    "\n",
    "## Goals:\n",
    "1. Extract sales data from Wordpress efficiently.\n",
    "2. Analyze and interpret the extracted data to provide meaningful insights.\n",
    "3. Generate comprehensive reports to aid in decision-making.\n",
    "\n",
    "## Working Environment:\n",
    "- The agents will work in a collaborative environment, each focusing on their specialized tasks.\n",
    "- Communication between agents will be streamlined to ensure smooth data flow and integration.\n",
    "- The agency will leverage WooCommerce's API for data extraction and Python libraries for data analysis and visualization.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating agent... DataAnalyst\n"
     ]
    }
   ],
   "source": [
    "from agency_swarm import Agency\n",
    "\n",
    "agency = Agency([\n",
    "    salesmgr,\n",
    "    [salesmgr, analyzer]\n",
    "], shared_instructions=agency_manifesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 6 backend functions\n",
       "-------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       "fn_index=1\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       "fn_index=2\n",
       " inputs:\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x00000207CB045CD0>\n",
       " outputs:\n",
       "fn_index=3\n",
       " inputs:\n",
       " |-<gradio.templates.Files object at 0x00000207CB06B910>\n",
       " outputs:\n",
       "fn_index=4\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       "fn_index=5\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x00000207CAD08C10>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x00000207CAF52DD0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message files:  []\n",
      "Images:  []\n",
      "THREAD:[ user -> SalesManager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_PQYW2IkiU9T0kolJ2hdcx3RW&mode=assistant&thread=thread_0v08Tr5fCUwIxhmyx428QfS7\n",
      "THREAD:[ SalesManager -> DataAnalyst ]: URL https://platform.openai.com/playground/assistants?assistant=asst_sZzwBuBLLJS1seqrbgOV4Eht&mode=assistant&thread=thread_9C4z2LVhLl4Bh24xVkdAkpYn\n"
     ]
    }
   ],
   "source": [
    "agency.demo_gradio(height=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
